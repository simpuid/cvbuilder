# CV Builder
- Katkar Prathamesh Shivaji `18114038`
- Priyanshu Garg `18114058`
- Ritesh Singh `18114067`
- Utkarsh `18114080`
- Yugantar Arya `18114084`

### Live Demo: [`CV Builder`](http://iitr-cvbuilder.herokuapp.com)
## Introduction
As placement or internship season of most of the colleges approaches to start, making __resume__ is a very hectic work for all the students. Also, many companies judge the candidature of a student just by his/her resume. __Resume__ is the recruitng company's __first impression__ of the student. So it is necessary for the student to think beyond the third dimension while making the resume.

So we made an __Online Resume Generation Portal__ to take the pressure off their mind and allow them to make a beautiful and competent resume by just filling their details.

## Problem Statement
The given project requires to develop a Resume Generation Portal for students so that they can create their resume effortlessly and get their resume just by filling up a simple form where data needs to be filled. The portal should come with pre-defined resume format. It should be user-friendly and easy enough for anyone to understand without any prior knowledge. The system should support the feature to download resume in PDF format. The system should be an online application that can be accessed throughout the organization and outside as well with proper login provided. It should be secured against misuse so that the students can trust you with their details. And also, the user can log in again to access the previous resume that he had made. The resume generated by system should follow the standard Format as stated by most of the Engineering Colleges of India.

## Solution
For the sake of simplicity, we divided the project into two components:
* A portal to add/update/remove data in the database
* A generator which queries the data and generates a pdf from it
Both components uses a common database to store and query the data.

#### Portal
The portal is a flask application with server side logic. It dynamically generates and serves webpages with the user's data and allows the user to add/change/remove their data.

#### Generator
The generator generates a `.xtx` xetex file using the data from the database. Finally the `.xtx` is converted to `.pdf` file and stored inside the database as `MEDIUMBLOB` in `resume_table`.

### Techologies Used
- __MySQL__
Used as Database server to store the data we get from our clients. MySQL was chosen beacuse it is easy to use and scalable if and when required.

- __Flask__
Flask is a python micro-framework which has been used as a server to serve the forms and and the download pages we designed. Its `micro` gave us a wide array of choices about which other technologies we could use.

- __HTML, Jinja2 and Bootstrap__
HTML was used to make the web pages of our website. Bootstrap is a CSS framework which helped us in customizing the webpages and making them more user-friendly. Jinja2 is a templating engine which was used to dynamically generate web pages with different data.

- __Docker__
Docker allowed us to easily pack, ship, and run our application as a lightweight, portable, self-sufficient container, which can run virtually anywhere. It saves us from the problem of changing project dependencies and configurations.

- __Xelatex__
Xelatex is a latex compiler used to convert the latex files generated by the system into pdf. The format of the `.xtx` file is XeTeX



## Entity Relationship Diagram

### Logical ER Diagram
![Logical ER Diagram](https://i.imgur.com/lC25cKG.png)

### Physical ER Diagram
![Physical ER Diagram](https://i.imgur.com/uNaGZTO.png)


## Our Approach
To generate resume, we need data (to be given by the client) and a place to store it (DBMS). We started off by listing what all data we have to take from our clients (students):
1. Personal Information (Name, Email, etc.)
2. Educational details (Tenth, Twelfth, Current CGPA)
3. Languages
4. Achievements
5. Skills/Profciencies
6. Extra-Curricular activites
7. Internships/Work Experience
8. Projects
9. References

We begun with a naive idea of having __all the data in one table__. It presented us with the following difficulties:
- Longer query response time: Fetching all the data in one query made it incredibly inefficient.
- Data Redundancy: It lead to insertion, deletion and updation anomalies.

So, we decided to divide the tables and made an __Entitiy-Relationship diagram__ to get a cleaner picture of the database structure to be made. We then __normalized__ (discussed in the upcoming section) the tables with the help of ER Diagram to further reduce data redundancies and remove anamolies.
Having a clear picture of the table structure helped us in optimizing the queries. We also used some MySQL specific clauses like `ON DUPLICATE KEY UPDATE` to further optimize our program.

## Normalization
We have normalized the tables upto __Boyce-Codd Normal Form (BCNF)__ for minimum data redundancy. There were a lot of tables which had to be normalize in our database. For example:

We have stored the projects a student has successfully completed in `project_table`. The primary key for the table is `(student_id, project_title)` which uniquely identifies each row of the table. The structure of the initial table is as follows:
#### project_table
| Key | Attribute | Type   |
|--------|---------------------|---------|
| PK, FK | student_id          | int     |
| PK     | project_title       | varchar |
|        | project_description | float   |
|        | project_start_date  | varchar |
|        | project_end_date    | int     |
|        | project_professor   | varchar |

Each project that a student performs can be supervised and evaluated by multiple professors. So, we were storing the emails of all the professors in `project_professors` attribute of `project_table`. This table structure fails __1st Normal Form__. So we divided rows into __multiple rows with 1 professor each__. Furthermore, we divided it into 2 diferent tables: `project_table` and `project_professor_table` for separation of concern and to further reduce data anamolies. The final table structure was as follows:
#### project_table
| Key | Attribute | Type   |
|--------|---------------------|---------|
| PK, FK | student_id          | int     |
| PK     | project_title       | varchar |
|        | project_description | float   |
|        | project_start_date  | varchar |
|        | project_end_date    | int     |
#### professor_table
| Key | Attribute | Type   |
|--------|---------------------|---------|
| PK, FK | student_id          | int     |
| PK, FK | professor_title     | varchar |
| PK, FK | professor_email     | varchar |



## Optimization
When user press the save button then we could either insert or update the record. It requires an extra query to check for existence of record. So the code would be like
```python
if student_record_exists(): # First query to check for existance
    student_record_update(data) # Conditioned second query
else:
    student_record_insert(data) # Conditioned second query
```
This 2 query process can be reduced to 1 query using `ON DUPLICATE KEY UPDATE`
for example
```sql
INSERT INTO student_table
VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
ON DUPLICATE KEY UPDATE
student_id = VALUES(student_id),
student_name = VALUES(student_name),
student_phone = VALUES(student_phone),
student_email = VALUES(student_email),
student_dob = VALUES(student_dob),
student_branch = VALUES(student_branch),
student_minor = VALUES(student_minor),
student_year = VALUES(student_year)
```
If the record exists then it will __update__ it otherwise __insert__ it.

## Query Optimization
The tables of the database are in __BCNF form__ which makes most of the queries simple and efficient. The only query with the scope of optimization is in the pdf generator module.
The pdf generator needs the data of all the __professors__ which are linked with __projects__ and __references__ of a particular project. To do this we need to get the __professors__' data linked with __projects__ together with __professors__' data linked with __references__ and union them together.
This leads to an unoptimized query like
```sql
SELECT professor_email, professor_department,
    professor_name, professor_phone
FROM
    (
        SELECT student_id, professor_email,
            professor_department, professor_name,
            professor_phone
        FROM project_professor_table 
        NATURAL JOIN professor_table
        UNION
        SELECT student_id, professor_email, 
            professor_department, professor_name,
            professor_phone
        FROM reference_table NATURAL JOIN professor_table
    ) as all_emails
WHERE student_id = 100
```
`SELECT` comes after `NATURAL JOIN` and `UNION` which makes the intermediate steps inefficient
It can be further optimized as
```sql
SELECT *
FROM
    (
        SELECT professor_email
        FROM project_professor_table
        WHERE student_id = 100
        UNION
        SELECT professor_email
        FROM reference_table
        WHERE student_id = 100
    ) as all_emails
    NATURAL JOIN professor_table
```
Here we `SELECT` the union of `professor_email`(which is the primary key for `professor_table`) from __projects__ and __references__ and then made a `NATURAL JOIN` with `professor_table` to get the professor data. This makes the intermediate steps of query efficient.


## Snapshots
### Login ![Login](https://i.imgur.com/UaGmLb5.png)

### Dashboard ![Dashboard](https://i.imgur.com/NrzqMY9.png)

### Student Form ![Student](https://i.imgur.com/urMZFG1.png)

### Project Form ![Project](https://i.imgur.com/hh1ScJm.png)

## Project Link
[Github Repository](https://github.com/simpuid/cvbuilder)

## Conclusion
We made an Online Resume Generator which generates resume for the user within no time by filling their required details. The resume can be tailored for specific needs of the students. We tried to implement all the necessary features that one needs while making a good resume at least on a B.Tech level. Our project is an example of how to integrate databases with web application in a portable way.
